{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cx2313_ly2637 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "from shapely import wkt\n",
    "import sqlalchemy as db\n",
    "\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import Column, Integer, Float, String, DateTime, create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"zipcodes\" / \"ZIP_CODE_040114.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"4P7xr8685SCdZVFOLXScTCqJi\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data Preprocessing\n",
    "\n",
    "The first part of the project involves two main activities. The initial step is to download specific datasets manually. This is followed by using Python scripts for automated data downloads. Once the data is collected, the next step is to sort through it. This includes selecting the relevant information, fixing any missing or incorrect data, and creating samples from these datasets for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load and clean data for zipcode file\n",
    "- For the zipcode file, first, we'll remove any columns that are not needed. Next, we'll review the basic information of the dataset. Following that, we'll identify the parts that need cleaning and proceed with the cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load data and remove unnecessary columns\n",
    "zipcode_data_file = DATA_DIR / \"nyc_zipcodes.shp\"\n",
    "gdf = gpd.read_file(zipcode_data_file)\n",
    "\n",
    "columns_to_keep = ['ZIPCODE', 'STATE', 'COUNTY', 'geometry']\n",
    "zipcode_gdf = gdf[columns_to_keep]\n",
    "\n",
    "# Rename columns for consistency\n",
    "zipcode_gdf = zipcode_gdf.rename(columns={'ZIPCODE': 'zipcode', 'City': 'city','COUNTY': 'county','STATE': 'state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   zipcode   263 non-null    object  \n",
      " 1   state     263 non-null    object  \n",
      " 2   county    263 non-null    object  \n",
      " 3   geometry  263 non-null    geometry\n",
      "dtypes: geometry(1), object(3)\n",
      "memory usage: 8.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>NY</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((1038098.252 188138.380, 1038141.936 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>NY</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((1001613.713 186926.440, 1002314.243 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>NY</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((1011174.276 183696.338, 1011373.584 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>NY</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((995908.365 183617.613, 996522.848 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>NY</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((991997.113 176307.496, 992042.798 17...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zipcode state  county                                           geometry\n",
       "0   11436    NY  Queens  POLYGON ((1038098.252 188138.380, 1038141.936 ...\n",
       "1   11213    NY   Kings  POLYGON ((1001613.713 186926.440, 1002314.243 ...\n",
       "2   11212    NY   Kings  POLYGON ((1011174.276 183696.338, 1011373.584 ...\n",
       "3   11225    NY   Kings  POLYGON ((995908.365 183617.613, 996522.848 18...\n",
       "4   11218    NY   Kings  POLYGON ((991997.113 176307.496, 992042.798 17..."
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: basic information of the data.\n",
    "print(zipcode_gdf.info())\n",
    "zipcode_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the results we observed, it's clear that the geometry column in the zipcode file is not in the WGS coordinate system. Therefore, we will need to include a transformation in our clean function to convert the geometries to the WGS system for consistency and analysis compatibility.\n",
    "\n",
    "- Furthermore, we will drop any duplicate rows to ensure data integrity and accuracy for our analysis and reporting. This step is crucial for maintaining the quality of our dataset and providing reliable insights.\n",
    "\n",
    "    - In our dataset, each zipcode is intended to correspond to a unique set of boundary data, representing a specific geographic area. This one-to-one relationship between a zipcode and its boundaries is crucial for the integrity and accuracy of our geographical analyses. Therefore, we have opted for a data cleaning approach that involves removing duplicate entries based solely on the `zipcode` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clean function\n",
    "def clean_zipcode_data(gdf):\n",
    "    gdf_cleaned = gdf.copy()\n",
    "    \n",
    "    # Change to WGS system for consistency\n",
    "    gdf_cleaned = gdf_cleaned.to_crs(epsg=4326)\n",
    "    \n",
    "    # Validate geometric data in 'geometry'\n",
    "    gdf_cleaned = gdf_cleaned[gdf_cleaned['geometry'].is_valid]\n",
    "\n",
    "    # Remove rows with any missing values\n",
    "    gdf_cleaned = gdf_cleaned.dropna()\n",
    "    \n",
    "    # Remove duplicates\n",
    "    gdf_cleaned = gdf_cleaned.drop_duplicates(subset='zipcode')\n",
    "\n",
    "    # Check that all zipcodes are 5 characters long\n",
    "    gdf_cleaned = gdf_cleaned[gdf_cleaned['zipcode'].apply(lambda x: len(str(x)) == 5)]\n",
    "\n",
    "    # Ensure categorical consistency\n",
    "    categorical_columns = ['state', 'county']\n",
    "    for col in categorical_columns:\n",
    "        gdf_cleaned.loc[:, col] = gdf_cleaned[col].str.title()\n",
    "    \n",
    "    return gdf_cleaned\n",
    "\n",
    "cleaned_zipcode_gdf = clean_zipcode_data(zipcode_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check cleaned data in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 248 entries, 0 to 262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   zipcode   248 non-null    object  \n",
      " 1   state     248 non-null    object  \n",
      " 2   county    248 non-null    object  \n",
      " 3   geometry  248 non-null    geometry\n",
      "dtypes: geometry(1), object(3)\n",
      "memory usage: 9.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>Ny</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((-73.80585 40.68291, -73.80569 40.682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>Ny</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.93740 40.67973, -73.93487 40.679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>Ny</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.90294 40.67084, -73.90223 40.668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>Ny</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.95797 40.67066, -73.95576 40.670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>Ny</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.97208 40.65060, -73.97192 40.650...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zipcode state  county                                           geometry\n",
       "0   11436    Ny  Queens  POLYGON ((-73.80585 40.68291, -73.80569 40.682...\n",
       "1   11213    Ny   Kings  POLYGON ((-73.93740 40.67973, -73.93487 40.679...\n",
       "2   11212    Ny   Kings  POLYGON ((-73.90294 40.67084, -73.90223 40.668...\n",
       "3   11225    Ny   Kings  POLYGON ((-73.95797 40.67066, -73.95576 40.670...\n",
       "4   11218    Ny   Kings  POLYGON ((-73.97208 40.65060, -73.97192 40.650..."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cleaned_zipcode_gdf.info())\n",
    "cleaned_zipcode_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the zipcode information for New York City, we need to extract this information to use as a reference. This will help us filter the data needed for `311`, `tree`, and `Zillow`. We will include this step in the cleaning steps for `tree`, `311`, and `Zillow` files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Download and clean data for trees \n",
    "- For the download part, due to the large volume of data, a script is implemented to download, process, and store New York City tree data in a GeoJSON file, handling the data in chunks to manage the size and complexity efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_geojson_data(url_base, filename, force=False):\n",
    "    limit = 50000  \n",
    "    offset = 0  \n",
    "    all_data = []\n",
    "\n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading data to {filename}...\")\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                params = {\n",
    "                    '$limit': limit,\n",
    "                    '$offset': offset,\n",
    "                    '$$app_token': \"4P7xr8685SCdZVFOLXScTCqJi\"\n",
    "                }\n",
    "                url_with_params = f\"{url_base}?{urllib.parse.urlencode(params)}\"\n",
    "                print(\"Requesting URL:\", url_with_params)\n",
    "                response = requests.get(url_with_params)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                data = response.json()\n",
    "                if not data['features']: \n",
    "                    break\n",
    "\n",
    "                all_data.extend(data['features'])\n",
    "                offset += limit\n",
    "            \n",
    "            geojson_feature_collection = {\n",
    "                \"type\": \"FeatureCollection\",\n",
    "                \"features\": all_data\n",
    "            }\n",
    "\n",
    "            with open(filename, \"w\") as f:\n",
    "                json.dump(geojson_feature_collection, f)\n",
    "\n",
    "            print(f\"Done downloading data to {filename}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filename}...\")\n",
    "\n",
    "    return filename\n",
    "\n",
    "nyc_tree_data_file = DATA_DIR / \"nyc_tree_data.geojson\"\n",
    "download_nyc_geojson_data(\"https://data.cityofnewyork.us/resource/5rq2-4hqu.geojson\", nyc_tree_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, we will use GeoPandas to read the GeoJSON file, and then examine the data for any inconsistencies or areas that may require cleaning.\n",
    "- Upon understanding the issues that require analysis, we will also select the necessary columns in this step, The columns we will use are `tree_id`, `zipcode`, `latitude`, `longitude`, `status`, `health`, `spc_common`, and `geometry`.\n",
    "\n",
    "In summary, regarding the tree data, our approach will be as follows: First, we will remove unnecessary columns. Second, we will examine the basic information of the data. Third, we will clean the data where necessary. Since we are using GeoPandas to read the GeoJSON data, the dataframe will include a column named 'geometry', which is already in the WGS coordinate system, so no further processing is required for this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load data and remove unnecessary columns.\n",
    "nyc_tree_data_file = DATA_DIR / \"nyc_tree_data.geojson\"\n",
    "\n",
    "geodf_tree_data=gpd.read_file(nyc_tree_data_file)\n",
    "columns_to_keep = ['tree_id', 'zipcode', 'latitude', 'longitude', 'status', 'health', 'spc_common', 'geometry']\n",
    "tree_gdf = geodf_tree_data[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 683788 entries, 0 to 683787\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count   Dtype   \n",
      "---  ------      --------------   -----   \n",
      " 0   tree_id     683788 non-null  object  \n",
      " 1   zipcode     683788 non-null  object  \n",
      " 2   latitude    683788 non-null  object  \n",
      " 3   longitude   683788 non-null  object  \n",
      " 4   status      683788 non-null  object  \n",
      " 5   health      652172 non-null  object  \n",
      " 6   spc_common  652169 non-null  object  \n",
      " 7   geometry    683788 non-null  geometry\n",
      "dtypes: geometry(1), object(7)\n",
      "memory usage: 41.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_id</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>status</th>\n",
       "      <th>health</th>\n",
       "      <th>spc_common</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180683</td>\n",
       "      <td>11375</td>\n",
       "      <td>40.72309177</td>\n",
       "      <td>-73.84421522</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Fair</td>\n",
       "      <td>red maple</td>\n",
       "      <td>POINT (-73.84422 40.72309)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200540</td>\n",
       "      <td>11357</td>\n",
       "      <td>40.79411067</td>\n",
       "      <td>-73.81867946</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Fair</td>\n",
       "      <td>pin oak</td>\n",
       "      <td>POINT (-73.81868 40.79411)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204026</td>\n",
       "      <td>11211</td>\n",
       "      <td>40.71758074</td>\n",
       "      <td>-73.9366077</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Good</td>\n",
       "      <td>honeylocust</td>\n",
       "      <td>POINT (-73.93661 40.71758)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204337</td>\n",
       "      <td>11211</td>\n",
       "      <td>40.71353749</td>\n",
       "      <td>-73.93445616</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Good</td>\n",
       "      <td>honeylocust</td>\n",
       "      <td>POINT (-73.93446 40.71354)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189565</td>\n",
       "      <td>11215</td>\n",
       "      <td>40.66677776</td>\n",
       "      <td>-73.97597938</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Good</td>\n",
       "      <td>American linden</td>\n",
       "      <td>POINT (-73.97598 40.66678)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tree_id zipcode     latitude     longitude status health       spc_common  \\\n",
       "0  180683   11375  40.72309177  -73.84421522  Alive   Fair        red maple   \n",
       "1  200540   11357  40.79411067  -73.81867946  Alive   Fair          pin oak   \n",
       "2  204026   11211  40.71758074   -73.9366077  Alive   Good      honeylocust   \n",
       "3  204337   11211  40.71353749  -73.93445616  Alive   Good      honeylocust   \n",
       "4  189565   11215  40.66677776  -73.97597938  Alive   Good  American linden   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (-73.84422 40.72309)  \n",
       "1  POINT (-73.81868 40.79411)  \n",
       "2  POINT (-73.93661 40.71758)  \n",
       "3  POINT (-73.93446 40.71354)  \n",
       "4  POINT (-73.97598 40.66678)  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: basic information of the data.\n",
    "print(tree_gdf.info())\n",
    "tree_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage with nan: 4.62%\n",
      "Number of duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "tree_with_nan = tree_gdf[tree_gdf.isnull().any(axis=1)]\n",
    "num_rows_with_nan = len(tree_with_nan)\n",
    "total_rows = len(tree_gdf)\n",
    "percent_with_nan = (num_rows_with_nan / total_rows) * 100\n",
    "\n",
    "print(f\"percentage with nan: {percent_with_nan:.2f}%\")\n",
    "print(f\"Number of duplicates: {tree_gdf.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output indicates that the GeoDataFrame contains 683,788 entries across 7 columns. Of these, only the `health` and \n",
    "`spc_common` columns have missing values, as all other columns have a non-null count of 683,788. \n",
    "\n",
    "Given that the `health` and `spc_common` columns cannot be effectively imputed, and after assessing that missing values account for only 4.62% of the total data, the decision to delete all rows with missing values is deemed reasonable. \n",
    "\n",
    "Due to the diverse nature of our tree datasets, it containing unique and valuable information, we have opted to remove duplicates only when an entire row is identical. This approach ensures the preservation of all distinct data points, crucial for our comprehensive analysis.\n",
    "\n",
    "- For example, a single tree_id might have several records that document various states of the same tree over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clean function\n",
    "def clean_tree_data(gdf):\n",
    "    gdf_cleaned = gdf.copy()\n",
    "    \n",
    "    # Filter based on zip codes present in the 'zipcode' dataframe\n",
    "    gdf_cleaned = gdf_cleaned[gdf_cleaned['zipcode'].isin(cleaned_zipcode_gdf['zipcode'])]\n",
    "    \n",
    "    # Convert 'latitude' and 'longitude' to float\n",
    "    gdf_cleaned['latitude'] = pd.to_numeric(gdf_cleaned['latitude'], errors='coerce')\n",
    "    gdf_cleaned['longitude'] = pd.to_numeric(gdf_cleaned['longitude'], errors='coerce')\n",
    "    \n",
    "    # Ensure categorical consistency\n",
    "    categorical_columns = ['status', 'health', 'spc_common']\n",
    "    for col in categorical_columns:\n",
    "        gdf_cleaned.loc[:, col] = gdf_cleaned[col].str.title() \n",
    "    \n",
    "    # Validate geometric data in 'geometry'\n",
    "    gdf_cleaned = gdf_cleaned[gdf_cleaned['geometry'].is_valid]\n",
    "    \n",
    "    # Remove duplicates\n",
    "    gdf_cleaned = gdf_cleaned.drop_duplicates()\n",
    "    \n",
    "    # Remove rows with missing values\n",
    "    gdf_cleaned = gdf_cleaned.dropna()\n",
    "    \n",
    "    return gdf_cleaned\n",
    "\n",
    "cleaned_tree_gdf = clean_tree_data(tree_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check clean data for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 652167 entries, 0 to 683787\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count   Dtype   \n",
      "---  ------      --------------   -----   \n",
      " 0   tree_id     652167 non-null  object  \n",
      " 1   zipcode     652167 non-null  object  \n",
      " 2   latitude    652167 non-null  float64 \n",
      " 3   longitude   652167 non-null  float64 \n",
      " 4   status      652167 non-null  object  \n",
      " 5   health      652167 non-null  object  \n",
      " 6   spc_common  652167 non-null  object  \n",
      " 7   geometry    652167 non-null  geometry\n",
      "dtypes: float64(2), geometry(1), object(5)\n",
      "memory usage: 44.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_id</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>status</th>\n",
       "      <th>health</th>\n",
       "      <th>spc_common</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180683</td>\n",
       "      <td>11375</td>\n",
       "      <td>40.723092</td>\n",
       "      <td>-73.844215</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Red Maple</td>\n",
       "      <td>POINT (-73.84422 40.72309)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200540</td>\n",
       "      <td>11357</td>\n",
       "      <td>40.794111</td>\n",
       "      <td>-73.818679</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Pin Oak</td>\n",
       "      <td>POINT (-73.81868 40.79411)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204026</td>\n",
       "      <td>11211</td>\n",
       "      <td>40.717581</td>\n",
       "      <td>-73.936608</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Good</td>\n",
       "      <td>Honeylocust</td>\n",
       "      <td>POINT (-73.93661 40.71758)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204337</td>\n",
       "      <td>11211</td>\n",
       "      <td>40.713537</td>\n",
       "      <td>-73.934456</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Good</td>\n",
       "      <td>Honeylocust</td>\n",
       "      <td>POINT (-73.93446 40.71354)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189565</td>\n",
       "      <td>11215</td>\n",
       "      <td>40.666778</td>\n",
       "      <td>-73.975979</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Good</td>\n",
       "      <td>American Linden</td>\n",
       "      <td>POINT (-73.97598 40.66678)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tree_id zipcode   latitude  longitude status health       spc_common  \\\n",
       "0  180683   11375  40.723092 -73.844215  Alive   Fair        Red Maple   \n",
       "1  200540   11357  40.794111 -73.818679  Alive   Fair          Pin Oak   \n",
       "2  204026   11211  40.717581 -73.936608  Alive   Good      Honeylocust   \n",
       "3  204337   11211  40.713537 -73.934456  Alive   Good      Honeylocust   \n",
       "4  189565   11215  40.666778 -73.975979  Alive   Good  American Linden   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (-73.84422 40.72309)  \n",
       "1  POINT (-73.81868 40.79411)  \n",
       "2  POINT (-73.93661 40.71758)  \n",
       "3  POINT (-73.93446 40.71354)  \n",
       "4  POINT (-73.97598 40.66678)  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cleaned_tree_gdf.info())\n",
    "cleaned_tree_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Download and clean data for 311 complaints\n",
    "- Regarding the 311 data, given its immense volume, we opted to filter the data during the downloading phase, after understanding the requirements for subsequent analysis. Initially, we filtered the data by date, selecting records between January 1, 2015, at 00:00:00 and September 30, 2023, at 23:59:59. Subsequently, we chose to download only the following columns: `latitude, longitude, incident_zip, created_date, location, complaint_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc311_geojson_data(url_base, filename, force=False):\n",
    "    start_date = '2015-01-01T00:00:00'\n",
    "    end_date = '2023-09-30T23:59:59'\n",
    "    limit = 2500000  \n",
    "    offset = 0 \n",
    "    all_data = []\n",
    "\n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading data to {filename}...\")\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                params = {\n",
    "                    '$where': f\"created_date between '{start_date}' and '{end_date}'\",\n",
    "                    '$limit': limit,\n",
    "                    '$offset': offset,\n",
    "                    '$$app_token': \"4P7xr8685SCdZVFOLXScTCqJi\",\n",
    "                    '$select': 'latitude,longitude,incident_zip,created_date,location,complaint_type'  \n",
    "                }\n",
    "                url_with_params = f\"{url_base}?{urllib.parse.urlencode(params)}\"\n",
    "                print(\"Requesting URL:\", url_with_params)\n",
    "                response = requests.get(url_with_params)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                data = response.json()\n",
    "                if not data['features']: \n",
    "                    break\n",
    "\n",
    "                all_data.extend(data['features'])  \n",
    "                offset += limit\n",
    "\n",
    "            geojson_feature_collection = {\n",
    "                \"type\": \"FeatureCollection\",\n",
    "                \"features\": all_data\n",
    "            }\n",
    "\n",
    "            with open(filename, \"w\") as f:\n",
    "                json.dump(geojson_feature_collection, f)\n",
    "\n",
    "            print(f\"Done downloading data to {filename}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filename}...\")\n",
    "\n",
    "    return filename\n",
    "\n",
    "nyc_311_data_file = DATA_DIR / \"nyc_311_data.geojson\"\n",
    "download_nyc311_geojson_data(\"https://data.cityofnewyork.us/resource/erm2-nwe9.geojson\", nyc_311_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, we will follow the same steps as we did when cleaning the tree data. First, we need to review the basic information of the data. Second, we need to identify which parts of the data require cleaning, and then write a clean function to address these issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load data\n",
    "nyc_311_data_file = DATA_DIR / \"nyc_311_data.geojson\"\n",
    "\n",
    "nyc311_gdf=gpd.read_file(nyc_311_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 24336507 entries, 0 to 24336506\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   latitude        object        \n",
      " 1   created_date    datetime64[ns]\n",
      " 2   longitude       object        \n",
      " 3   incident_zip    object        \n",
      " 4   complaint_type  object        \n",
      " 5   geometry        geometry      \n",
      "dtypes: datetime64[ns](1), geometry(1), object(4)\n",
      "memory usage: 1.1+ GB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>created_date</th>\n",
       "      <th>longitude</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.655672001198894</td>\n",
       "      <td>2023-09-30 23:59:58</td>\n",
       "      <td>-73.95917686020623</td>\n",
       "      <td>11226</td>\n",
       "      <td>Noise - Street/Sidewalk</td>\n",
       "      <td>POINT (-73.95918 40.65567)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.76675595839554</td>\n",
       "      <td>2023-09-30 23:59:38</td>\n",
       "      <td>-73.78751847563191</td>\n",
       "      <td>11361</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>POINT (-73.78752 40.76676)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.71949965458691</td>\n",
       "      <td>2023-09-30 23:59:35</td>\n",
       "      <td>-73.98486650733275</td>\n",
       "      <td>10002</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>POINT (-73.98487 40.71950)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.687499303408536</td>\n",
       "      <td>2023-09-30 23:59:34</td>\n",
       "      <td>-73.7972903094197</td>\n",
       "      <td>11435</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>POINT (-73.79729 40.68750)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.65220215349917</td>\n",
       "      <td>2023-09-30 23:59:28</td>\n",
       "      <td>-73.9579464603267</td>\n",
       "      <td>11226</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>POINT (-73.95795 40.65220)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             latitude        created_date           longitude incident_zip  \\\n",
       "0  40.655672001198894 2023-09-30 23:59:58  -73.95917686020623        11226   \n",
       "1   40.76675595839554 2023-09-30 23:59:38  -73.78751847563191        11361   \n",
       "2   40.71949965458691 2023-09-30 23:59:35  -73.98486650733275        10002   \n",
       "3  40.687499303408536 2023-09-30 23:59:34   -73.7972903094197        11435   \n",
       "4   40.65220215349917 2023-09-30 23:59:28   -73.9579464603267        11226   \n",
       "\n",
       "            complaint_type                    geometry  \n",
       "0  Noise - Street/Sidewalk  POINT (-73.95918 40.65567)  \n",
       "1      Noise - Residential  POINT (-73.78752 40.76676)  \n",
       "2       Noise - Commercial  POINT (-73.98487 40.71950)  \n",
       "3      Noise - Residential  POINT (-73.79729 40.68750)  \n",
       "4      Noise - Residential  POINT (-73.95795 40.65220)  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: basic information of the data.\n",
    "print(nyc311_gdf.info())\n",
    "nyc311_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage with nan: 5.37%\n",
      "Number of duplicates: 907072\n"
     ]
    }
   ],
   "source": [
    "nyc311_with_nan = nyc311_gdf[nyc311_gdf.isnull().any(axis=1)]\n",
    "num_rows_with_nan = len(nyc311_with_nan)\n",
    "total_rows = len(nyc311_gdf)\n",
    "percent_with_nan = (num_rows_with_nan / total_rows) * 100\n",
    "\n",
    "print(f\"percentage with nan: {percent_with_nan:.2f}%\")\n",
    "print(f\"Number of duplicates: {nyc311_gdf.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['latitude', 'longitude', 'incident_zip', 'geometry']\n"
     ]
    }
   ],
   "source": [
    "# Print columns with missing values\n",
    "columns_with_missing_values = nyc311_gdf.columns[nyc311_gdf.isnull().any()].tolist()\n",
    "print(columns_with_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output indicates that the GeoDataFrame contains 24336507 entries across 6 columns. Of these, `latitude`, `longtitude` and \n",
    "`incident_zip` columns have missing values.\n",
    "\n",
    "Additionally, we can observe that there are a total of 907072 identical rows. These will be removed in the subsequent cleaning steps.\n",
    "\n",
    "- When two rows in the dataset are completely identical across all their fields, it typically indicates a case of duplication. Such duplicates don't add any additional value or information. In fact, they can skew analysis and results if not addressed. Therefore, in the upcoming data cleaning steps, one of each pair of identical rows will be removed. \n",
    "\n",
    "Given that the `latitude`, `longtitude` and `incident_zip` columns cannot be effectively imputed, and after assessing that missing values account for only 5.37% of the total data, the decision to delete all rows with missing values is deemed reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clean function\n",
    "def clean_311_data(gdf):\n",
    "    gdf_cleaned = gdf.copy()\n",
    "    \n",
    "    # Rename 'incident_zip' to 'zipcode' for consistant in later mapping\n",
    "    gdf_cleaned.rename(columns={'incident_zip': 'zipcode'}, inplace=True)\n",
    "    \n",
    "    # Filter based on zip codes present in the 'zipcode' dataframe\n",
    "    gdf_cleaned = gdf_cleaned[gdf_cleaned['zipcode'].isin(cleaned_zipcode_gdf['zipcode'])]\n",
    "    \n",
    "    # Convert 'latitude' and 'longitude' to float\n",
    "    gdf_cleaned['latitude'] = pd.to_numeric(gdf_cleaned['latitude'], errors='coerce')\n",
    "    gdf_cleaned['longitude'] = pd.to_numeric(gdf_cleaned['longitude'], errors='coerce')\n",
    "    \n",
    "    # Validate geometric data in 'geometry'\n",
    "    gdf_cleaned = gdf_cleaned[gdf_cleaned['geometry'].is_valid]\n",
    "    \n",
    "    # Remove duplicates\n",
    "    gdf_cleaned = gdf_cleaned.drop_duplicates()\n",
    "    \n",
    "    # Remove rows with missing values\n",
    "    gdf_cleaned = gdf_cleaned.dropna(subset=['latitude', 'longitude', 'zipcode'])\n",
    "    \n",
    "    return gdf_cleaned\n",
    "\n",
    "cleaned_311_gdf = clean_311_data(nyc311_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 22233352 entries, 0 to 24336505\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   latitude        float64       \n",
      " 1   created_date    datetime64[ns]\n",
      " 2   longitude       float64       \n",
      " 3   zipcode         object        \n",
      " 4   complaint_type  object        \n",
      " 5   geometry        object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(3)\n",
      "memory usage: 1.2+ GB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>created_date</th>\n",
       "      <th>longitude</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.655672</td>\n",
       "      <td>2023-09-30 23:59:58</td>\n",
       "      <td>-73.959177</td>\n",
       "      <td>11226</td>\n",
       "      <td>Noise - Street/Sidewalk</td>\n",
       "      <td>POINT (-73.95917686020623 40.655672001198894)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.766756</td>\n",
       "      <td>2023-09-30 23:59:38</td>\n",
       "      <td>-73.787518</td>\n",
       "      <td>11361</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>POINT (-73.78751847563191 40.76675595839554)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.719500</td>\n",
       "      <td>2023-09-30 23:59:35</td>\n",
       "      <td>-73.984867</td>\n",
       "      <td>10002</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>POINT (-73.98486650733275 40.71949965458691)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.687499</td>\n",
       "      <td>2023-09-30 23:59:34</td>\n",
       "      <td>-73.797290</td>\n",
       "      <td>11435</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>POINT (-73.7972903094197 40.687499303408536)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.652202</td>\n",
       "      <td>2023-09-30 23:59:28</td>\n",
       "      <td>-73.957946</td>\n",
       "      <td>11226</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>POINT (-73.9579464603267 40.65220215349917)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude        created_date  longitude zipcode           complaint_type  \\\n",
       "0  40.655672 2023-09-30 23:59:58 -73.959177   11226  Noise - Street/Sidewalk   \n",
       "1  40.766756 2023-09-30 23:59:38 -73.787518   11361      Noise - Residential   \n",
       "2  40.719500 2023-09-30 23:59:35 -73.984867   10002       Noise - Commercial   \n",
       "3  40.687499 2023-09-30 23:59:34 -73.797290   11435      Noise - Residential   \n",
       "4  40.652202 2023-09-30 23:59:28 -73.957946   11226      Noise - Residential   \n",
       "\n",
       "                                        geometry  \n",
       "0  POINT (-73.95917686020623 40.655672001198894)  \n",
       "1   POINT (-73.78751847563191 40.76675595839554)  \n",
       "2   POINT (-73.98486650733275 40.71949965458691)  \n",
       "3   POINT (-73.7972903094197 40.687499303408536)  \n",
       "4    POINT (-73.9579464603267 40.65220215349917)  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cleaned_311_gdf.info())\n",
    "cleaned_311_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Load and clean data for Historical monthly average rents by zip code from Zillow\n",
    "- For the Zillow data, since our entire project is focused on New York City, we will first need to filter for data pertaining to NYC. Then, based on our understanding of the requirements for subsequent analysis, we will retain the columns that are useful.\n",
    "\n",
    "- According to the subsequent analysis requirements, we only need to reserve the rental prices of 2023-08-31, 2023-01-31 and 2023-09-31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load data and remove unnecessary columns\n",
    "zillow_data_file = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "df = pd.read_csv(zillow_data_file)\n",
    "\n",
    "columns_to_keep = ['2023-08-31','2023-01-31','2023-09-30','RegionName','City','CountyName']\n",
    "zillow_df = df[columns_to_keep]\n",
    "\n",
    "# Rename columns for consistency\n",
    "zillow_df = zillow_df.rename(columns={'RegionName': 'zipcode','City': 'city','CountyName': 'county'})\n",
    "zillow_df = zillow_df.rename(columns = {'2023-08-31':'date_2023_08_31','2023-01-31':'date_2023_01_31','2023-09-30':'date_2023_09_30'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6722 entries, 0 to 6721\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   date_2023_08_31  6251 non-null   float64\n",
      " 1   date_2023_01_31  4816 non-null   float64\n",
      " 2   date_2023_09_30  6722 non-null   float64\n",
      " 3   zipcode          6722 non-null   int64  \n",
      " 4   city             6665 non-null   object \n",
      " 5   county           6722 non-null   object \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 315.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_2023_08_31</th>\n",
       "      <th>date_2023_01_31</th>\n",
       "      <th>date_2023_09_30</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2053.486247</td>\n",
       "      <td>2027.438438</td>\n",
       "      <td>2055.771355</td>\n",
       "      <td>77494</td>\n",
       "      <td>Katy</td>\n",
       "      <td>Fort Bend County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1795.384582</td>\n",
       "      <td>1738.217986</td>\n",
       "      <td>1799.631140</td>\n",
       "      <td>77449</td>\n",
       "      <td>Katy</td>\n",
       "      <td>Harris County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1757.602011</td>\n",
       "      <td>1706.900064</td>\n",
       "      <td>1755.031490</td>\n",
       "      <td>77084</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Harris County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1488.180414</td>\n",
       "      <td>1458.063897</td>\n",
       "      <td>1494.366097</td>\n",
       "      <td>79936</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3064.476503</td>\n",
       "      <td>2895.699421</td>\n",
       "      <td>3079.585783</td>\n",
       "      <td>11385</td>\n",
       "      <td>New York</td>\n",
       "      <td>Queens County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_2023_08_31  date_2023_01_31  date_2023_09_30  zipcode      city  \\\n",
       "0      2053.486247      2027.438438      2055.771355    77494      Katy   \n",
       "1      1795.384582      1738.217986      1799.631140    77449      Katy   \n",
       "2      1757.602011      1706.900064      1755.031490    77084   Houston   \n",
       "3      1488.180414      1458.063897      1494.366097    79936   El Paso   \n",
       "4      3064.476503      2895.699421      3079.585783    11385  New York   \n",
       "\n",
       "             county  \n",
       "0  Fort Bend County  \n",
       "1     Harris County  \n",
       "2     Harris County  \n",
       "3    El Paso County  \n",
       "4     Queens County  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: basic information of the data.\n",
    "print(zillow_df.info())\n",
    "zillow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the output above, We see many missing rent prices in the data, so we need to fill these in. This will help us get a full and accurate picture of rent changes over time.\n",
    "\n",
    "- We decided to estimate the missing monthly rents by carrying forward the last recorded price and then using the following known price when necessary. This makes sense because rent doesn't usually change too much from month to month. If we have a missing price, it's a safe bet that it was close to what it was the month before, or it will be similar to the price after. That's why we use these filling methods; they're like educated guesses that keep things simple and sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clean function \n",
    "def clean_zillow_data(df):\n",
    "    # Convert 'zipcode' to an object for consistency with other datasets\n",
    "    df['zipcode'] = df['zipcode'].astype(str)\n",
    "    \n",
    "    # Filter based on zip codes present in the 'zipcode' dataframe\n",
    "    df = df[df['zipcode'].isin(cleaned_zipcode_gdf['zipcode'])]\n",
    "    \n",
    "    # Fill missing data row-wise using forward-fill and then backward-fill\n",
    "    df = df.fillna(method='ffill', axis=0)\n",
    "    df = df.fillna(method='bfill', axis=0)\n",
    "\n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Ensure categorical consistency\n",
    "    categorical_columns = ['city', 'county']\n",
    "    for col in categorical_columns:\n",
    "        df.loc[:, col] = df[col].str.title() \n",
    "    \n",
    "    return df\n",
    "\n",
    "cleaned_zillow_df = clean_zillow_data(zillow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 146 entries, 4 to 6721\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   date_2023_08_31  146 non-null    float64\n",
      " 1   date_2023_01_31  146 non-null    float64\n",
      " 2   date_2023_09_30  146 non-null    float64\n",
      " 3   zipcode          146 non-null    object \n",
      " 4   city             146 non-null    object \n",
      " 5   county           146 non-null    object \n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 8.0+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_2023_08_31</th>\n",
       "      <th>date_2023_01_31</th>\n",
       "      <th>date_2023_09_30</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3064.476503</td>\n",
       "      <td>2895.699421</td>\n",
       "      <td>3079.585783</td>\n",
       "      <td>11385</td>\n",
       "      <td>New York</td>\n",
       "      <td>Queens County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2737.547470</td>\n",
       "      <td>2588.030194</td>\n",
       "      <td>2728.733333</td>\n",
       "      <td>11208</td>\n",
       "      <td>New York</td>\n",
       "      <td>Kings County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2285.460026</td>\n",
       "      <td>2588.030194</td>\n",
       "      <td>2362.500000</td>\n",
       "      <td>11236</td>\n",
       "      <td>New York</td>\n",
       "      <td>Kings County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2353.686402</td>\n",
       "      <td>2155.617718</td>\n",
       "      <td>2423.888889</td>\n",
       "      <td>10467</td>\n",
       "      <td>New York</td>\n",
       "      <td>Bronx County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2302.557354</td>\n",
       "      <td>2255.604528</td>\n",
       "      <td>2292.994444</td>\n",
       "      <td>11373</td>\n",
       "      <td>New York</td>\n",
       "      <td>Queens County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date_2023_08_31  date_2023_01_31  date_2023_09_30 zipcode      city  \\\n",
       "4       3064.476503      2895.699421      3079.585783   11385  New York   \n",
       "6       2737.547470      2588.030194      2728.733333   11208  New York   \n",
       "12      2285.460026      2588.030194      2362.500000   11236  New York   \n",
       "13      2353.686402      2155.617718      2423.888889   10467  New York   \n",
       "14      2302.557354      2255.604528      2292.994444   11373  New York   \n",
       "\n",
       "           county  \n",
       "4   Queens County  \n",
       "6    Kings County  \n",
       "12   Kings County  \n",
       "13   Bronx County  \n",
       "14  Queens County  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cleaned_zillow_df.info())\n",
    "cleaned_zillow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we have four cleaned data:**\n",
    "- cleaned_tree_gdf\n",
    "- cleaned_311_gdf\n",
    "- cleaned_zillow_df\n",
    "- cleaned_zipcode_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First step we have to create the data base and postgis extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createdb: error: database creation failed: ERROR:  database \"FinalProject\" already exists\n",
      "ERROR:  extension \"postgis\" already exists\n"
     ]
    }
   ],
   "source": [
    "! /Applications/Postgres.app/Contents/Versions/latest/bin/createdb 'FinalProject'\n",
    "! /Applications/Postgres.app/Contents/Versions/latest/bin/psql --dbname 'FinalProject' -c 'CREATE EXTENSION postgis;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this part, we've set up a database using SQLAlchemy and PostgreSQL to manage data related to trees, 311 service requests, zipcode and Zillow. We first created classes. After defining these classes, We generated the corresponding tables in the database. We also created a function for data convertion which is from dataframe to sql. Finally, we saved the SQL schema to a file named `schema.sql` for future reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, Float, String, Text, DateTime, MetaData\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from geoalchemy2 import Geometry\n",
    "from sqlalchemy.schema import CreateTable\n",
    "\n",
    "engine = create_engine('postgresql://xcq:x@localhost/FinalProject')\n",
    "Base = declarative_base()\n",
    "\n",
    "class Three_11(Base):\n",
    "    __tablename__ = \"three_11s\"\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    zipcode = Column(Integer)\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)\n",
    "    created_date = Column(DateTime)\n",
    "    geometry = Column(Geometry('POINT'))  \n",
    "    complaint_type = Column(String)\n",
    "    \n",
    "class Tree(Base):\n",
    "    __tablename__ = \"trees\"\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    tree_id = Column(String)\n",
    "    zipcode = Column(Integer)\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)\n",
    "    status = Column(String)\n",
    "    health = Column(String)\n",
    "    spc_common = Column(String)\n",
    "    geometry = Column(Geometry('POINT')) \n",
    "    \n",
    "class Zipcode(Base):\n",
    "    __tablename__ = \"zipcodes\"\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    zipcode = Column(Integer)\n",
    "    area = Column(String)\n",
    "    state = Column(String)\n",
    "    county = Column(String)\n",
    "    geometry = Column(Geometry('POLYGON')) \n",
    "\n",
    "\n",
    "class Zillow(Base):\n",
    "    __tablename__ = \"zillows\"\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    zipcode = Column(Integer)\n",
    "    city = Column(String)\n",
    "    county = Column(String)\n",
    "    date_2023_08_31 = Column(Float) \n",
    "    date_2023_01_31 = Column(Float)\n",
    "    date_2023_09_30 = Column(Float)\n",
    "    \n",
    "Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData(bind=engine)\n",
    "metadata.reflect()\n",
    "\n",
    "with open('schema.sql', 'w') as f:\n",
    "    for table in Base.metadata.tables.values():\n",
    "        f.write(str(CreateTable(table)))\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_geodataframe_to_sql(gdf, table_name, engine, if_exists='replace', index=False):\n",
    "    \"\"\"\n",
    "    Writes a GeoDataFrame to a PostgreSQL database table.\n",
    "\n",
    "    Parameters:\n",
    "    gdf (GeoDataFrame): The GeoDataFrame to be written to the database.\n",
    "    table_name (str): Name of the target database table.\n",
    "    engine: SQLAlchemy database engine.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert geometry to WKT format.\n",
    "    # gdf['geometry'] = gdf['geometry'].apply(lambda geom: geom.wkt if geom is not None else None)\n",
    "    gdf.to_sql(table_name, engine, if_exists=if_exists, index=index)\n",
    "\n",
    "\n",
    "def write_dataframe_to_sql(df, table_name, engine, if_exists='replace', index=False):\n",
    "    \"\"\"\n",
    "    Writes a DataFrame to a PostgreSQL database table.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame to be written to the database.\n",
    "    table_name (str): Name of the target database table.\n",
    "    engine: SQLAlchemy database engine.\n",
    "    \"\"\"\n",
    "\n",
    "    df.to_sql(table_name, engine, if_exists=if_exists, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/vwgvzrmn3kb9gnqyl0268qfh0000gn/T/ipykernel_31889/3339454612.py:12: UserWarning: Geometry column does not contain geometry.\n",
      "  gdf['geometry'] = gdf['geometry'].apply(lambda geom: geom.wkt if geom is not None else None)\n"
     ]
    }
   ],
   "source": [
    "write_geodataframe_to_sql(cleaned_tree_gdf, 'trees', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_geodataframe_to_sql(cleaned_311_gdf, 'three_11s', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/vwgvzrmn3kb9gnqyl0268qfh0000gn/T/ipykernel_31889/3339454612.py:12: UserWarning: Geometry column does not contain geometry.\n",
      "  gdf['geometry'] = gdf['geometry'].apply(lambda geom: geom.wkt if geom is not None else None)\n"
     ]
    }
   ],
   "source": [
    "write_geodataframe_to_sql(cleaned_zipcode_gdf, 'zipcodes', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe_to_sql(cleaned_zillow_df,'zillows',engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Understanding Data\n",
    "\n",
    "- In Part 3, We will be crafting a set of SQL queries to develop a better understanding of the datasets we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_to_file(query, outfile):\n",
    "    \"\"\"\n",
    "    Writes a given SQL query to a sql file.\n",
    "    Args:\n",
    "        query: The SQL query string.\n",
    "        outfile: The file path where the query will be written.\n",
    "    \"\"\"\n",
    "    with open(outfile, 'w') as file:\n",
    "        file.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following output shows the number of 311 complaints per zip code between October 1st, 2022 and September 30th, 2023 (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('11226', 46373)\n",
      "('10467', 44757)\n",
      "('11385', 42856)\n",
      "('10468', 42122)\n",
      "('10452', 41314)\n",
      "('10457', 39151)\n",
      "('11201', 38888)\n",
      "('10458', 38801)\n",
      "('11207', 38166)\n",
      "('10456', 37270)\n",
      "('10453', 35941)\n",
      "('11208', 35049)\n",
      "('10031', 32186)\n",
      "('11221', 31901)\n",
      "('10466', 31438)\n",
      "('10032', 30564)\n",
      "('10025', 30020)\n",
      "('10462', 29545)\n",
      "('11238', 29314)\n",
      "('11368', 28495)\n",
      "('11230', 28491)\n",
      "('11220', 28221)\n",
      "('11235', 27216)\n",
      "('11216', 26866)\n",
      "('10019', 26656)\n",
      "('11225', 26655)\n",
      "('10023', 26501)\n",
      "('11214', 26161)\n",
      "('10463', 25970)\n",
      "('11212', 25721)\n",
      "('11377', 25673)\n",
      "('11203', 25540)\n",
      "('11101', 25423)\n",
      "('10460', 25379)\n",
      "('11234', 24897)\n",
      "('11222', 24833)\n",
      "('10027', 24810)\n",
      "('11211', 24809)\n",
      "('11215', 24735)\n",
      "('10002', 24729)\n",
      "('11209', 24644)\n",
      "('11206', 24565)\n",
      "('11218', 24368)\n",
      "('11213', 24299)\n",
      "('10472', 24195)\n",
      "('11233', 23845)\n",
      "('11223', 23629)\n",
      "('11373', 23266)\n",
      "('10033', 22656)\n",
      "('11237', 22628)\n",
      "('11229', 22296)\n",
      "('11236', 21712)\n",
      "('10461', 21636)\n",
      "('10034', 21234)\n",
      "('11204', 21209)\n",
      "('10011', 21199)\n",
      "('10003', 20886)\n",
      "('10469', 20508)\n",
      "('10026', 20457)\n",
      "('11210', 20135)\n",
      "('10029', 20053)\n",
      "('10009', 20009)\n",
      "('11217', 19982)\n",
      "('11372', 19853)\n",
      "('10451', 19741)\n",
      "('10036', 19683)\n",
      "('10314', 19424)\n",
      "('11231', 19315)\n",
      "('11419', 19162)\n",
      "('11432', 19111)\n",
      "('10459', 19094)\n",
      "('11420', 18991)\n",
      "('10040', 18861)\n",
      "('11378', 18821)\n",
      "('11375', 18578)\n",
      "('11219', 18394)\n",
      "('11355', 18336)\n",
      "('11366', 18114)\n",
      "('10035', 17673)\n",
      "('10455', 17566)\n",
      "('10030', 16983)\n",
      "('11421', 16807)\n",
      "('11205', 16748)\n",
      "('10312', 16575)\n",
      "('11434', 16228)\n",
      "('11435', 16172)\n",
      "('10016', 16151)\n",
      "('11414', 16033)\n",
      "('10024', 15638)\n",
      "('10306', 15353)\n",
      "('11691', 15119)\n",
      "('11103', 15085)\n",
      "('10473', 15075)\n",
      "('11106', 14641)\n",
      "('11379', 14412)\n",
      "('11105', 13977)\n",
      "('11433', 13910)\n",
      "('10465', 13858)\n",
      "('11224', 13724)\n",
      "('10028', 13687)\n",
      "('11354', 13617)\n",
      "('10301', 13135)\n",
      "('10454', 12978)\n",
      "('10014', 12935)\n",
      "('10001', 12790)\n",
      "('11249', 12770)\n",
      "('11357', 12646)\n",
      "('11369', 12365)\n",
      "('10304', 12173)\n",
      "('10013', 12129)\n",
      "('11102', 12025)\n",
      "('11374', 11987)\n",
      "('11232', 11956)\n",
      "('11417', 11754)\n",
      "('11365', 11739)\n",
      "('11228', 11695)\n",
      "('10128', 11443)\n",
      "('11418', 11401)\n",
      "('10012', 11194)\n",
      "('10039', 11171)\n",
      "('11239', 10894)\n",
      "('10305', 10618)\n",
      "('11358', 10386)\n",
      "('11413', 10299)\n",
      "('11412', 10075)\n",
      "('10309', 9743)\n",
      "('11356', 9687)\n",
      "('10022', 9523)\n",
      "('11104', 9334)\n",
      "('10021', 9247)\n",
      "('11361', 8842)\n",
      "('10470', 8645)\n",
      "('11367', 8494)\n",
      "('11416', 8287)\n",
      "('11423', 8121)\n",
      "('11694', 8108)\n",
      "('10065', 7832)\n",
      "('10010', 7724)\n",
      "('11422', 7676)\n",
      "('10037', 7565)\n",
      "('11436', 7385)\n",
      "('10471', 7380)\n",
      "('10018', 7145)\n",
      "('11370', 7121)\n",
      "('11364', 6882)\n",
      "('10308', 6636)\n",
      "('10017', 6584)\n",
      "('10038', 6583)\n",
      "('10310', 6540)\n",
      "('10303', 6442)\n",
      "('10474', 6373)\n",
      "('10302', 6071)\n",
      "('11429', 5906)\n",
      "('10075', 5557)\n",
      "('11415', 5450)\n",
      "('11411', 5447)\n",
      "('11692', 5281)\n",
      "('11428', 5258)\n",
      "('11427', 4837)\n",
      "('11693', 4159)\n",
      "('11426', 4033)\n",
      "('10007', 4004)\n",
      "('11360', 3784)\n",
      "('10307', 3717)\n",
      "('10475', 3626)\n",
      "('11362', 3170)\n",
      "('11430', 3055)\n",
      "('10464', 2505)\n",
      "('10004', 2445)\n",
      "('11004', 2343)\n",
      "('10005', 2060)\n",
      "('11363', 1844)\n",
      "('11109', 1823)\n",
      "('10006', 1565)\n",
      "('10044', 1007)\n",
      "('11001', 807)\n",
      "('10282', 735)\n",
      "('11040', 636)\n",
      "('10069', 591)\n",
      "('10280', 548)\n",
      "('10020', 429)\n",
      "('10169', 389)\n",
      "('10121', 286)\n",
      "('10107', 215)\n",
      "('10278', 204)\n",
      "('10105', 160)\n",
      "('10153', 153)\n",
      "('11359', 146)\n",
      "('11697', 109)\n",
      "('10172', 100)\n",
      "('10151', 83)\n",
      "('10103', 81)\n",
      "('10281', 68)\n",
      "('10168', 60)\n",
      "('10118', 52)\n",
      "('11005', 50)\n",
      "('10120', 48)\n",
      "('10106', 45)\n",
      "('11251', 41)\n",
      "('10162', 38)\n",
      "('10119', 35)\n",
      "('10271', 33)\n",
      "('10041', 33)\n",
      "('10112', 28)\n",
      "('10045', 27)\n",
      "('10165', 27)\n",
      "('10110', 24)\n",
      "('10171', 24)\n",
      "('10048', 23)\n",
      "('10170', 23)\n",
      "('10154', 22)\n",
      "('10158', 21)\n",
      "('10178', 20)\n",
      "('11371', 20)\n",
      "('10123', 17)\n",
      "('10174', 16)\n",
      "('10279', 15)\n",
      "('10177', 13)\n",
      "('10115', 12)\n",
      "('10111', 12)\n",
      "('10176', 8)\n",
      "('10152', 7)\n",
      "('10166', 7)\n",
      "('10173', 5)\n",
      "('10167', 4)\n",
      "('10122', 4)\n",
      "('10155', 4)\n",
      "('00083', 2)\n",
      "('10055', 2)\n",
      "('10080', 1)\n",
      "('10175', 1)\n"
     ]
    }
   ],
   "source": [
    "QUERY_1_FILENAME = QUERY_DIR / \"calm_to_live_in_area.sql\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT \"zipcode\" AS \"Incident Zip\", COUNT(*) AS num_complaints\n",
    "FROM three_11s\n",
    "WHERE \"created_date\" >= '2022-10-01' AND \"created_date\" <= '2023-09-30'\n",
    "GROUP BY \"zipcode\"\n",
    "ORDER BY num_complaints DESC;\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(QUERY_1)\n",
    "    rows = result.fetchall()\n",
    "\n",
    "    \n",
    "for row in rows:\n",
    "    print(row)\n",
    "    \n",
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following output shows the 10 zip codes have the most trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('10312', 21356)\n",
      "('10314', 16330)\n",
      "('10306', 12616)\n",
      "('10309', 12105)\n",
      "('11234', 10838)\n",
      "('11385', 10262)\n",
      "('11357', 9016)\n",
      "('11207', 8293)\n",
      "('11208', 7896)\n",
      "('11434', 7833)\n"
     ]
    }
   ],
   "source": [
    "QUERY_2_FILENAME = QUERY_DIR / \"10_most_tree_area.sql\"\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT zipcode, COUNT(*) AS total_trees\n",
    "FROM trees\n",
    "WHERE status = 'Alive'\n",
    "GROUP BY zipcode\n",
    "ORDER BY total_trees DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(QUERY_2)\n",
    "    rows = result.fetchall()\n",
    "\n",
    "    \n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following output shows the average rent in 10 area with the most trees by zipcodes, for the month of August 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('11385', '3,064.48')\n",
      "('11208', '2,737.55')\n",
      "('11207', '3,079.09')\n",
      "('11234', '2,312.31')\n",
      "('10314', '2,465.47')\n",
      "('11434', '2,645.92')\n",
      "('10312', '1,775.09')\n",
      "('10306', '2,331.54')\n",
      "('11357', '2,458.81')\n",
      "('10309', '1,832.01')\n"
     ]
    }
   ],
   "source": [
    "QUERY_3_FILENAME = QUERY_DIR / \"avg_rent_most_tree_area.sql\"\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "SELECT z.zipcode, TO_CHAR(z.\"date_2023_08_31\", 'FM9,999,999.00') as average_rent\n",
    "FROM (\n",
    "    SELECT t.zipcode\n",
    "    FROM trees t\n",
    "    WHERE status = 'Alive'\n",
    "    GROUP BY t.zipcode\n",
    "    ORDER BY COUNT(t.zipcode) DESC\n",
    "    LIMIT 10\n",
    ") as top_zipcodes\n",
    "JOIN zillows z ON z.zipcode = top_zipcodes.zipcode\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(QUERY_3)\n",
    "    rows = result.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following output shows the 5 highest and lowest average rent area by zipcodes and also include the tree count and complaint count of each for January 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4_FILENAME = QUERY_DIR / \"correlation_rent_trees_311\"\n",
    "\n",
    "QUERY_4 = \"\"\"\n",
    "WITH RentData AS (\n",
    "    SELECT zipcode, \n",
    "           TO_CHAR(CAST(\"date_2023_01_31\" AS FLOAT), 'FM9,999,999.00') AS average_rent\n",
    "    FROM zillows),\n",
    "    \n",
    "TreeCount AS (\n",
    "    SELECT zipcode, \n",
    "           COUNT(*) AS tree_count\n",
    "    FROM trees\n",
    "    GROUP BY zipcode),\n",
    "    \n",
    "ComplaintCount AS (\n",
    "    SELECT zipcode, \n",
    "           COUNT(*) AS complaint_count\n",
    "    FROM three_11s\n",
    "    GROUP BY zipcode),\n",
    "    \n",
    "Combined AS (\n",
    "    SELECT r.zipcode, \n",
    "           r.average_rent, \n",
    "           COALESCE(t.tree_count, 0) AS tree_count, \n",
    "           COALESCE(c.complaint_count, 0) AS complaint_count\n",
    "    FROM RentData r\n",
    "    LEFT JOIN TreeCount t ON r.zipcode = t.zipcode\n",
    "    LEFT JOIN ComplaintCount c ON r.zipcode = c.zipcode)\n",
    "SELECT * FROM (\n",
    "    SELECT * FROM Combined\n",
    "    ORDER BY average_rent DESC\n",
    "    LIMIT 5) HighRent\n",
    "UNION ALL\n",
    "SELECT * FROM (\n",
    "    SELECT * FROM Combined\n",
    "    ORDER BY average_rent ASC\n",
    "    LIMIT 5) LowRent\n",
    "\"\"\"\n",
    "\n",
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(QUERY_4)\n",
    "    rows = result.fetchall()\n",
    "\n",
    "    \n",
    "for row in rows:\n",
    "    print(row)\n",
    "    \n",
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following output shows the 10 zip codes have the most trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5_FILENAME = QUERY_DIR / \"rewrite_query_2\"\n",
    "\n",
    "QUERY_5 = \"\"\"\n",
    "SELECT z.zipcode, COUNT(*) AS total_trees\n",
    "FROM zipcodes z\n",
    "JOIN trees t ON z.zipcode = t.zipcode\n",
    "WHERE ST_Within(t.geometry, z.geometry) AND t.status = 'Alive'\n",
    "GROUP BY z.zipcode\n",
    "ORDER BY total_trees DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(QUERY_5)\n",
    "    rows = result.fetchall()\n",
    "\n",
    "    \n",
    "for row in rows:\n",
    "    print(row)\n",
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The output shows all the trees that are within  mile radius of Latitude: 40.80737875669467, Longitude: -73.96253174434912. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(\".\")\n",
    "QUERY_6_FILENAME = QUERY_DIR / \"tress_0.5miles_near_campus\"\n",
    "\n",
    "QUERY_6 = \"\"\"\n",
    "SELECT treeid, species, health, status, ST_AsText(geometry) AS location\n",
    "FROM trees\n",
    "WHERE ST_DWithin(\n",
    "    geometry, \n",
    "    ST_Transform(ST_GeomFromText('POINT(-73.96253174434912 40.80737875669467)', 4326), 4326),\n",
    "    804.67\n",
    ")\n",
    "\"\"\"\n",
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
